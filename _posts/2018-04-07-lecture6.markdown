---
layout: post
title:  "Двойственность линейного программирования"
ref: lecture6
date:   2018-04-07
categories: lecture
---

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script src="{{site.baseurl}}/tsi-inlineDisqussions-919f4a1/inlineDisqussions.js"></script>
<link rel="stylesheet" type="text/css" href="{{site.baseurl}}/tsi-inlineDisqussions-919f4a1/inlineDisqussions.css" />
<script>
  disqus_shortname = 'balit-ski';
  jQuery(document).ready(function() {
    jQuery("p").inlineDisqussions();
  });
</script>



## ---1.18---
Пришло время познакомиться с элементами выпуклой двойственности. Для нас это будет тот "правильный" геометрический язык, на котором оптимизационные утверждения доказываются просто. Ключевое утверждение, по сути своей детский вариант линейной двойственности, -- лемма Фаркаша -- наиболее удачно доказывается на языке двойственных конусов. Введём этот язык.

Непустое множество \\(C \subset \mathbb{R}^n\\) называется _выпуклым конусом_, если \\(\lambda x + \mu y \in C\\) для любых \\(x,y \in C\\), \\(\lambda, \mu \ge 0\\). Конус, _порождённый_ набором векторов \\(X \subset \mathbb{R}^n\\), определяется как
\\[
\text{cone } X = \\{\lambda_1 x_1 + \ldots + \lambda_n x_n ~|~ \lambda_i \ge 0, x_i \in X\\}.
\\]

_Полярным конусом_ по отношению к конусу \\(C\\) называется конус
\\[
C^\circ = \\{y \in \mathbb{R}^n ~|~ \langle x,y \rangle \le 0 ~ \forall x \in C\\}.
\\]

Треугольными скобками я обозначаю обычное скалярное произведение \\(\langle x,y \rangle = x^T y = x_1 y_1 + \ldots + x_n y_n\\).

<span style="display:block;text-align:center">
![Полярный конус](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Polar_cone_illustration.svg/220px-Polar_cone_illustration.svg.png "Полярный конус")
</span>


> **Лемма [Farkas, 1902].** Пусть даны матрица \\(A \in \mathbb{R}^{m \times n}\\) и вектор-столбец \\(b \in \mathbb{R}^{m}\\). Тогда из следующих двух альтернатив <sup id="fnref:1"> <a href="#fn:1" rel="footnote">1</a> </sup> выполнена ровно одна:
* либо разрешима система \\(Ax=b\\), \\(x \ge 0\\);
* либо разрешима система \\(A^Ty\ge0\\), \\(b^T y < 0\\).

_Доказательство._ 
Рассмотрим выпуклый конус <sup id="fnref:2"> <a href="#fn:2" rel="footnote">2</a> </sup>
\\[
C = \\{ Ax ~\|~  x \ge 0 \\} \subset \mathbb{R}^m.
\\]  
Ясно, что это конус, порождённый столбцами матрицы \\(A\\).
Полярный к нему конус есть не что иное как 
\\[
C^\circ = \\{y ~\|~ A^Ty \ge0\\}.
\\]
В самом деле,
\\[
y \in C^\circ \quad \Leftrightarrow
\\]
\\[
\langle z,y \rangle \le 0 ~ \forall z \in C \quad \Leftrightarrow
\\] 
\\[
\langle Ax,y \rangle \le 0 ~ \forall x \ge 0 \quad \Leftrightarrow
\\]
\\[
\langle x, A^T y \rangle \le 0 ~ \forall x \ge 0 \quad \Leftrightarrow
\\]
(подставляя вместо \\(x\\) базисные вектора \\(\mathbb{R}^n\\))
\\[
A^T y \le 0.
\\]

Первая альтернатива выполнена, если вектор \\(b\\) лежит в конусе \\(C\\). Предположим, что она не выполнена. Тогда \\(b \notin C\\). Мы имеем точку вне замкнутого выпуклого множества -- стандартная идея заключается в том, чтобы отделить точку от множества гиперплоскостью. Для этого нам понадобится какой-нибудь вариант теоремы отделимости. В нашем конечномерном случае это утверждение геометрически очевидно. Например, рассмотрим ближайшую к \\(b\\) точку \\(d\\) конуса \\(С\\) (восполните детали: почему такая точка существует?). Тогда гиперплоскость \\(H\\), проходящая через \\(d\\) перпендикулярно отрезку \\(bd\\) и есть разделяющая гиперплоскость в следующем смысле. Пусть \\(H\\) задана как \\(H = \\{z \in \mathbb{R}^m ~\|~ \langle z, y \rangle = 0\\}\\)<sup id="fnref:3"> <a href="#fn:3" rel="footnote">3</a> </sup> для какого-то \\(y \in \mathbb{R}^m\\). Тогда \\(\langle b, y \rangle < 0\\) и \\(\langle z, y \rangle \ge 0 ~\forall z \in C\\). Таким образом мы нашли \\(y \in C^\circ\\), такой что \\(b^T y < 0\\), что и требовалось.
\\(\square\\) 

Для расширения нашего кругозора докажем другую версию леммы Фаркаша.

> **Лемма [Farkas once again].** Система линейных неравенств \\(Ax \le b\\), \\(x\ge 0\\) разрешима относительно \\(x\\) тогда и только тогда, когда \\(b^T y \ge 0\\) для любого вектора \\(y \ge 0\\), удовлетворяющего \\(A^Ty \ge 0\\).

_Доказательство._ 
Рассмотрим выпуклый конус
\\[
C = \\{ Ax ~\|~  x \ge 0 \\} + \\{z \le 0\\}.
\\] 
Сумма здесь -- так называемая _сумма Минковского_, которая определена как множество всевозможных сумм \\(y + z, y \in \\{ Ax ~\|~  x \ge 0 \\}, z \le 0\\).
Полярный к \\(C\\) конус есть
\\[
C^\circ = \\{ Ax ~\|~  x \ge 0 \\}^\circ \cap \\{z \le 0\\}^\circ.
\\]

Здесь мы воспользовались, что полярная двойственность переводит сумму Минковского в пересечение:
\\[
d \in (C_1 + C_2)^\circ \quad \Leftrightarrow
\\]
\\[
\langle d, c_1 + c_2 \rangle \le 0 ~\forall c_1 \in C_1, c_2 \in C_2 \quad \Leftrightarrow
\\]
(подставляя \\(c_1 = 0\\) и \\(c_2=0\\) по отдельности)
\\[
\langle d, c_1\rangle \le 0 \text{ и }  \langle d,  c_2 \rangle \le 0 ~\forall c_1 \in C_1, c_2 \in C_2 \quad \Leftrightarrow
\\]
\\[
d \in C_1^\circ \cap  C_2^\circ.
\\]
Тогда имеем:
\\[
C^\circ = \\{y ~\|~ A^Ty \ge0\\} \cap \\{y \ge 0\\} = \\{y \ge 0 ~\|~ A^Ty \ge0\\}.
\\]
Как и в предыдущей версии, либо \\(b \in C\\), либо отделяя \\(b\\) от \\(C\\) гиперплоскостью с нормалью \\(y\\), мы найдём \\(y \in C^\circ\\), удовлетворяющий \\(b^Ty <0\\), что эквивалентно утверждению леммы.
\\(\square\\)  

> **Лемма [Farkas one more time].** Система линейных неравенств \\(Ax \le b\\) несовместна в том и только том случае, когда положительная линейная комбинация некоторых её неравенств даёт абсурдное неравенство \\(0 \le -1\\).

_Доказательство._ 
В одну сторону утверждение очевидно: если из системы следует неравенство \\(0 \le -1\\), то решений у неё нет. Для рассуждения в обратную сторону воспользуемся той же идеологией, что и в предыдущих двух случаях. Если система \\(Ax \le b\\) несовместна, то точка \\(b \neq 0\\) не лежит в конусе
\\[
C = \\{ Ax ~\|~  x \in \mathbb{R}^n\\} + \\{z \le 0\\}.
\\]
Тогда отделяя \\(b\\) от \\(C\\) гиперплоскостью с нормалью \\(y\\), мы найдём \\(y \in C^\circ\\), удовлетворяющий \\(b^Ty <0\\).
С другой стороны,
\\[
C^\circ = \\{y ~\|~ A^Ty = 0\\} \cap \\{y \ge 0\\} = \\{y \ge 0 ~\|~ A^Ty = 0\\}.
\\]
Найденный \\(y \ge 0\\) даёт нам неотрицательные коэффициенты для линейной комбинации \\(y^T A = 0\\) строк матрицы \\(A\\). Тем самым мы вывели из неравенств системы абсурдное неравенство 
\\[
0 = y^T A x \le y^T b < 0.
\\]
Чтобы получить неравенство \\(0<1\\), мы можем поделить коэффициенты \\(y\\) на \\(|y^T b|\\).
\\(\square\\) 

## ---1.19---

Наконец, мы добрались до задачи линейного программирования. Главный результат для нас, естественно обобщающий многочисленные аналоги леммы Холла, -- _сильная теорема линейной двойственности_, которую мы легко выведем из леммы Фаркаша. Теорема даёт двойственный взгляд на такую задачу оптимизации: найти максимум линейной функции \\(c^T x\\) на полиэдре \\(\\{Ax \le b\\}\\). 

> **Теорема [von Neumann, 1947; Gale--Kuhn--Tucker, 1951].** Для любых \\(A \in \mathbb{R}^{m \times n}\\), \\(b \in \mathbb{R}^{m}\\), \\(c \in \mathbb{R}^{n}\\) выполнено равенство
\\[
\max \\{c^T x ~\|~ Ax \le b\\} = \min \\{b^T y ~\|~ y\ge 0, A^T y = c\\},
\\]
если хотя бы один из оптимумов конечен.

_Доказательство._ 
Заметим, что неравенство \\(\le\\) в теореме очевидно, потому что \\(c^Tx = y^T A x \le y^T b\\). Это утверждение называют _слабой теоремой двойственности_ (линейного программирования). Разность правой части и левой тогда неотрицательна и называется _зазором двойственности_. Мы покажем, что в задаче линейного программирования этот зазор нулевой (при условии, что одна из частей конечна).

Рассмотрим три случая.

1. Если \\(\min \\{b^T y ~\|~ y\ge 0, A^T y = c\\} = -\infty\\), то из слабой двойственности система \\(Ax \le b\\) неразрешима, и левая часть тоже равна \\(-\infty\\).

2. Если \\(\min \\{b^T y ~\|~ y\ge 0, A^T y = c\\} = +\infty\\), то по условию левая часть конечна, и в частности существует хотя бы один вектор \\(x_0\\), такой что \\(Ax_0 \le b\\). Так как система \\(A^T y = c\\), \\(y\ge 0\\) неразрешима, то по лемме Фаркаша существует \\(x\\), такой что \\(Ax \ge 0, c^T x < 0\\). Тогда рассматривая вектор \\(x_0 - tx\\) для сколь угодно большого \\(t \in \mathbb{R}\\), мы увидим, что что левая часть на самом деле равна \\(+\infty\\).

3. Если \\(\min \\{b^T y ~\|~ y\ge 0, A^T y = c\\} = m\\) конечен, то пусть этот минимум достигается на каком-то векторе \\(y_0\\). Предположим, что утверждение теоремы неверно, и что система \\(c^T x \ge m, Ax \le b\\) несовместна. Иными словами, система
\\[
\begin{pmatrix} A \\\ -c^T \end{pmatrix} x \le \begin{pmatrix} b \\\ -m \end{pmatrix}
\\]
несовместна. По лемме Фаркаша тогда следующая система совместна:
\\[
\begin{cases}
\begin{pmatrix} A \\\ -c^T \end{pmatrix}^T \begin{pmatrix} y \\\ t \end{pmatrix} = 0 \\\
\begin{pmatrix} b \\\ -m \end{pmatrix} \begin{pmatrix} y \\\ t \end{pmatrix} < 0 \\\ 
\begin{pmatrix} y \\\ t \end{pmatrix} \ge 0
\end{cases}
\\]
Если \\(t=0\\), мы можем переписать это как
\\[
\begin{cases}
A^T y = 0 \\\ b^T y < 0 \\\ y \ge 0
\end{cases}
\\]
Рассматривая тогда \\(y_0 + y\\), мы получаем противоречие с тем, что \\(m\\) было минимумом в нашей двойственной задаче линейного программирования. В самом деле, \\(y_0 + y \ge 0\\), \\(A^T(y_0+y) =  A^T y_0 = c\\) и \\(b^T (y_0+y) < b^T y_0 = m\\).
Значит, \\(t > 0\\), и перемасштабируя вектор \\(\begin{pmatrix} y \\\ t \end{pmatrix}\\), так что \\(t=1\\), мы получаем: 
\\[
\begin{cases}
A^T y = c \\\
b^T y < m \\\
y \ge 0
\end{cases}
\\]

\\[
\begin{cases} A^T y = c \\\ b^T y < m \\\ y \ge 0
\end{cases}
\\]
Опять же это противоречит тому, что \\(m\\) было минимумом.
\\(\square\\) 

Как и у леммы Фаркаша, у этого утверждения много ипостасей. Аналогичным образом можно  доказать следующие утверждения.

> **Теорема.** Для любых \\(A \in \mathbb{R}^{m \times n}\\), \\(b \in \mathbb{R}^{m}\\), \\(c \in \mathbb{R}^{n}\\) выполнено каждое из следующих равенств при условии, что хотя бы один из двух из оптимумов конечен.
1. 
\\[
\max \\{c^T x ~\|~ x \ge 0, Ax \le b\\} = \min \\{b^T y ~\|~ y\ge 0, A^T y \ge c\\};
\\]
2. 
\\[
\max \\{c^T x ~\|~ x \ge 0, Ax = b\\} = \min \\{b^T y ~\|~ A^T y \ge c\\}.
\\]

Две задачи на оптимум в левой и правой частях называются _прямой_ и _двойственной_ (по отношению друг к другу) задачами линейного программирования. Вы можете заметить паттерн и угадать, как двойственная задача строится по прямой в наиболее общем виде, когда ограничения заданы совокупностью равенств и неравенств разных видов. Например, каждому  неравенству в прямой задаче отвечает неотрицательная переменная в двойственной задаче; матрицы транспонируются; и так далее.

В качестве полезного упражнения можно проследить, как теорема двойственности влечёт теоремы Эгервари и Форда--Фалкерсона. 

Задачи линейного программирования хороши ещё тем, что для них существуют полиномиальные <sup id="fnref:4"> <a href="#fn:4" rel="footnote">4</a> </sup> алгоритмы _внутренней точки_.

<ol>
  <li id="fn:1">
    <p>
      Сравните с альтернативой Фредгольма!
    </p>
    <a href="#fnref:1" rev="footnote">↩</a>
  </li>

  <li id="fn:2">
    <p>
      Всякий раз, когда я пишу неравенство на вектора, подразумевается, что оно выполняется покомпонентно. 
	</p>
    <a href="#fnref:2" rev="footnote">↩</a>
  </li>

  <li id="fn:3">
    <p>
      Наша гиперплоскость проходит через начало координат, потому что "касается" конуса.
	</p>
    <a href="#fnref:3" rev="footnote">↩</a>
  </li>

  <li id="fn:4">
    <p>
      Статус этого утверждения нужно, конечно, уточнить, оговаривая, что должно быть рациональным, и как время работы зависит от длины входа с учётом длины записи всех участвующих во входе чисел.
	</p>
    <a href="#fnref:4" rev="footnote">↩</a>
  </li>
  
  
</ol> 